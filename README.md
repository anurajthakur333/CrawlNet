# ğŸŒ CrawlNet

An intelligent web scraping platform with automated order tracking for OnlineHomeShop.com, featuring a React frontend with Clerk authentication and a FastAPI backend.

## ğŸš€ Features

- **ğŸ” Clerk Authentication**: Secure user authentication with protected routes
- **ğŸ“Š Order Scraping**: Automated scraping of OnlineHomeShop orders
- **ğŸ’¾ MongoDB Storage**: Persistent order data storage
- **ğŸ“± Modern UI**: Beautiful React interface with Blueprint.js components
- **âš¡ FastAPI Backend**: High-performance Python API
- **ğŸ”§ Simple Configuration**: Minimal environment setup

## ğŸ—ï¸ Project Structure

```
ğŸŒCrawlNet/
â”œâ”€â”€ src/                    # React frontend
â”‚   â”œâ”€â”€ components/         # React components
â”‚   â”œâ”€â”€ pages/             # Page components
â”‚   â””â”€â”€ main.tsx           # App entry point
â”œâ”€â”€ backend/               # FastAPI backend
â”‚   â”œâ”€â”€ main.py            # FastAPI server
â”‚   â”œâ”€â”€ scraper.py         # Web scraping logic
â”‚   â”œâ”€â”€ start_server.py    # Server startup script
â”‚   â”œâ”€â”€ requirements.txt   # Python dependencies
â”‚   â”œâ”€â”€ venv/              # Python virtual environment
â”‚   â””â”€â”€ .env               # Backend environment variables
â”œâ”€â”€ .env                   # Frontend environment variables
â”œâ”€â”€ package.json           # Frontend dependencies
â””â”€â”€ README.md
```

## ğŸ› ï¸ Prerequisites

- **Node.js** (v16+)
- **Python** (v3.8+)
- **MongoDB** (local or cloud)
- **Chrome/Chromium** (for web scraping)

## âš™ï¸ Setup Instructions

### 1. Clone and Install Dependencies

```bash
# Clone the repository
git clone <your-repo-url>
cd CrawlNet

# Install frontend dependencies
npm install

# Set up backend (automated setup)
cd backend
./setup.sh
cd ..
```

**Alternative manual backend setup:**
```bash
cd backend
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
cd ..
```

### 2. Environment Configuration

#### Frontend Environment (`.env`)
```bash
# API Configuration
VITE_API_URL=http://localhost:8000

# Clerk Authentication (get from https://clerk.dev)
VITE_CLERK_PUBLISHABLE_KEY=pk_test_your_clerk_key_here

# Development
VITE_DEV=true
```

#### Backend Environment (`backend/.env`)
```bash
# CORS Configuration
CORS_ORIGINS=http://localhost:3000,http://localhost:5173,http://127.0.0.1:3000,http://127.0.0.1:5173

# MongoDB Configuration
MONGO_URI=mongodb://localhost:27017

# OnlineHomeShop Credentials
OHS_EMAIL=your_email@example.com
OHS_PASSWORD=your_password

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=True
```

### 3. Clerk Authentication Setup

1. Go to [Clerk.dev](https://clerk.dev) and create an account
2. Create a new project
3. Copy your **Publishable Key** from the dashboard
4. Add it to your `.env` file as `VITE_CLERK_PUBLISHABLE_KEY`

### 4. MongoDB Setup

**Option A: Local MongoDB**
```bash
# Install MongoDB locally (macOS with Homebrew)
brew install mongodb/brew/mongodb-community
brew services start mongodb/brew/mongodb-community
```

**Option B: MongoDB Atlas (Cloud)**
```bash
# Get connection string from MongoDB Atlas
# Update MONGO_URI in backend/.env
MONGO_URI=mongodb+srv://username:password@cluster.mongodb.net/
```

## ğŸš€ Running the Application

### Start the Backend

```bash
cd backend
source venv/bin/activate  # Activate virtual environment
python start_server.py    # Start FastAPI server
```

The API will be available at: `http://localhost:8000`
- Health check: `http://localhost:8000/health`
- API docs: `http://localhost:8000/docs`

### Start the Frontend

```bash
# In a new terminal, from project root
npm run dev
```

The frontend will be available at: `http://localhost:5173`

## ğŸ” Authentication Flow

1. **Public Access**: Landing page is accessible to everyone
2. **Protected Routes**: `/ohs` requires authentication
3. **Sign In**: Users can sign in via Clerk modal or dedicated page
4. **Navigation**: OHS button only shows when user is signed in

## ğŸ“Š API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Health check and configuration |
| `/orders` | GET | Scrape fresh orders and return data |
| `/orders_db` | GET | Get orders from database |
| `/orders_db` | DELETE | Clear all orders from database |

## ğŸ› Troubleshooting

### Common Issues

**1. Module Not Found Errors**
```bash
# If you get "ModuleNotFoundError", recreate the virtual environment
cd backend
rm -rf venv           # Remove broken environment
./setup.sh            # Use automated setup script
# OR manually:
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

**2. Clerk Authentication Errors**
```bash
# Check your .env file has the correct Clerk key
VITE_CLERK_PUBLISHABLE_KEY=pk_test_your_actual_key
```

**3. MongoDB Connection Issues**
```bash
# Check MongoDB is running
brew services list | grep mongodb
# Or check connection string for Atlas
```

**4. CORS Errors**
```bash
# Ensure your frontend URL is in CORS_ORIGINS
CORS_ORIGINS=http://localhost:3000,http://localhost:5173
```

**5. Scraper Issues**

**Test the scraper directly:**
```bash
cd backend
source venv/bin/activate
python test_scraper.py
```

**Common scraper problems:**
- **"Could not find orders table"**: The website structure may have changed, or login failed
- **"CAPTCHA detected"**: Manual intervention required - try logging in manually first
- **"Login failed"**: Check your OHS_EMAIL and OHS_PASSWORD in `backend/.env`
- **Chrome driver issues**: Update Chrome browser or try running with `SCRAPER_HEADLESS=False`

**Debug files**: When scraper fails, it creates debug HTML files:
- `debug_page_source.html` - Page source when orders table not found
- `login_debug_page_source.html` - Page source when login fails
- `captcha_page_source.html` - Page source when CAPTCHA detected

**Manual testing**: Set `SCRAPER_HEADLESS=False` in `scraper.py` to see what's happening:
```python
SCRAPER_HEADLESS = False  # Change this line in scraper.py
```

## ğŸ”§ Development Scripts

```bash
# Frontend
npm run dev        # Start development server
npm run build      # Build for production
npm run preview    # Preview production build

# Backend
cd backend
python start_server.py     # Start FastAPI server
python scraper.py          # Run scraper directly
python main.py             # Alternative server start
```

## ğŸ“ Environment Variables Reference

### Frontend Variables
| Variable | Default | Description |
|----------|---------|-------------|
| `VITE_API_URL` | `http://localhost:8000` | Backend API URL |
| `VITE_CLERK_PUBLISHABLE_KEY` | _(required)_ | Clerk authentication key |
| `VITE_DEV` | `true` | Development mode flag |

### Backend Variables
| Variable | Default | Description |
|----------|---------|-------------|
| `CORS_ORIGINS` | `localhost URLs` | Comma-separated list of allowed origins |
| `MONGO_URI` | `mongodb://localhost:27017` | MongoDB connection string |
| `OHS_EMAIL` | _(required)_ | OnlineHomeShop login email |
| `OHS_PASSWORD` | _(required)_ | OnlineHomeShop password |
| `API_HOST` | `0.0.0.0` | FastAPI server host |
| `API_PORT` | `8000` | FastAPI server port |
| `DEBUG` | `True` | Enable debug logging and auto-reload |

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature-name`
3. Commit changes: `git commit -am 'Add feature'`
4. Push to branch: `git push origin feature-name`
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License.

---

**Built with â¤ï¸ by [Anuraj](https://anuraj.online)** 